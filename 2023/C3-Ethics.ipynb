{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "5a3b8c1b-a2dc-4056-b19d-46f34999dded",
            "metadata": {
                "cell_name": "header_cell"
            },
            "source": [
                "<div style=\"background:#E9FFF6; color:#440404; padding:8px; border-radius: 4px; text-align: center; font-weight: 500;\">IFN619 - Data Analytics for Strategic Decision Makers (2023_sem1)</div>"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "b4657c87-4b4c-4b2f-8d3d-a16f14854cc1",
            "metadata": {
                "cell_name": "title_cell"
            },
            "source": [
                "# IFN619 :: C3 - Ethical considerations in data analytics\n",
                "\n",
                "#### IMPORTANT: Access this module in Canvas for 2 videos that walk through the content below"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "cc6d88b8",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "## Trust and other human factors"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fd0007c4",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "### Without cues for depth...\n",
                "\n",
                "[Strata 2013: Kate Crawford, \"Algorithmic Illusions: Hidden Biases of Big Data\"](https://youtu.be/irP5RCdpilc)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f386f9f6",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "### MathWashing\n",
                "\n",
                " [What is Math washing?](http://www.mathwashing.com)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e43f4036",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "### Machine Bias\n",
                "\n",
                "[Machine Bias — ProPublica](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "50d3ea80",
            "metadata": {},
            "source": [
                "### Kinds of Bias\n",
                "\n",
                "[Bias in Computer Systems - Friedman & Nissenbaum (1996)](https://nissenbaum.tech.cornell.edu/papers/Bias%20in%20Computer%20Systems.pdf)\n",
                "\n",
                "1. Pre-existing Bias\n",
                "    * Individual\n",
                "    * Societal\n",
                "2. Technical Bias\n",
                "    * Computer tools\n",
                "    * Decontextualized Algorithms\n",
                "    * Random number generation\n",
                "    * Formalization of Human Constructs\n",
                "3. Emergent Bias\n",
                "    * New Societal Knowledge\n",
                "    * Mismatch between users and system design\n",
                "        * Different expertise\n",
                "        * Different values\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "13822c32",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "### Assumptions\n",
                "\n",
                "[Challenging Dangerous Assumptions by Andy Cohen](https://youtu.be/So89DJ1Rckc)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "77d09abd",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "### Algorithmic responsibility\n",
                "\n",
                "[Algorithmic Accountability: A Primer](https://apo.org.au/sites/default/files/resource-files/2018-04/apo-nid142131.pdf)\n",
                "\n",
                "1. Fairness and Bias\n",
                "2. Opacity and Transparency\n",
                "3. Repurposing Data and Repurposing Algorithms\n",
                "4. Lack of Standards for Auditing\n",
                "5. Power and Control\n",
                "6. Trust and Expertise"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "bf4e5859",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "### What kind of action?\n",
                "\n",
                "* Awareness of own perspectives -  [20 lessons on bias in machine learning systems from NIPS 2017 Keynote](https://hub.packtpub.com/20-lessons-bias-machine-learning-systems-nips-2017/)\n",
                "* Laws and regulation about data - [How GDPR Drives Real-Time Analytics](https://datafloq.com/read/gdpr-drives-real-time-analytics/4824?mkt_tok=eyJpIjoiWldNeVlURXlNV0kxTkRJeCIsInQiOiI0bWZVSzJvYlQzNGZkaXQ3Mzc1S1RsTFFyR0E1bHpHbG1DR3dqMHhNUlVcL01VdTV3dW03Q3VaZHRkcG9pZWlUbUlQMVltMFozR0E5N2VKZHduK3pQOWl3UFJ6UFgyUEFjaXJtbldXMGVZclhHZTBxS3BWQ2hrM281M29aRnRXRUoifQ%3D%3D)\n",
                "* Understanding segmenting and marginalised groups -  [Google Developers Blog: Text Embedding Models Contain Bias. Here’s Why That Matters.](https://developers.googleblog.com/2018/04/text-embedding-models-contain-bias.html?m=1)\n",
                "* Consideration of user privacy\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "56d6a7e4",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "### The Social Dilemma\n",
                "\n",
                "[The Social Dilemma Of Driverless Cars | Iyad Rahwan | TEDxCambridge](https://youtu.be/nhCh1pBsS80)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "74322478",
            "metadata": {},
            "source": [
                "### Model Positionality and Computational Reflexivity\n",
                "\n",
                "Read the CHI'22 paper by [Cambo & Gergle - Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data Science](https://dl.acm.org/doi/pdf/10.1145/3491102.3501998).\n",
                "\n",
                "Watch a video that unpacks some [key aspects of positionality and reflexivity]()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4a1cc58d",
            "metadata": {},
            "source": []
        }
    ],
    "metadata": {
        "creation_period": "",
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.16"
        },
        "nb_name": "template",
        "qut": {
            "creation_period": "2023_sem1",
            "nb_name": "C3-Ethics",
            "unit_code": "IFN619"
        },
        "unit_code": ""
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
