{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3B: Advanced Numerical Techniques and Potential Ethical Concerns (part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "Neural Networks are one of the most powerfull techniques in Computer Science. They are computational systems vaguely inspired by the biological neural networks of animal brains.\n",
    "\n",
    "The image shows two neurons connected with each other. In this image, we can identify three important properties:\n",
    "\n",
    "- **Dendrites:** correspond to the input \"wires\" that receive sensory information. Dendrites are the segments of the neuron that receive stimulation in order for the cell to become active. They conduct electrical messages to the neuron cell body for the cell to function\n",
    "\n",
    "- **Axon:** corresponds to the body of the neuron. It is a long slender projection of a nerve cell, or neuron, that conducts electrical impulses away from the neuron's cell body or soma.\n",
    "\n",
    "- **Synapses:** correspond to the output \"wires\". When a nerve impulse reaches the synapse at the end of a neuron, it cannot pass directly to the next one. Instead, it triggers the neuron to release a chemical neurotransmitter. The neurotransmitter drifts across the gap between the two neurons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"./images/neuron.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rosenblatt's Perceptron: the first neuron\n",
    "\n",
    "A neuron is a computational unit that receives a number of **inputs** through the **dendrites**, performs some **computations** and then it sends **outputs** to the **synapses** via the **axon** to the other neurons in the brain. Neurons communicate with each other through some pulses of electricity also called spikes.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/800/1*o7aTsRvL1NocOCHqYTKi2g.png\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that data is linearly separable, the goal of the perceptron is to correctly classify the set of patterns into one of two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions in Neural Networks (and Deep Neural Networks)\n",
    "\n",
    "<img src='https://www.pyimagesearch.com/wp-content/uploads/2018/12/keras_conv2d_activation_functions.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember the Machine Learning Process:\n",
    "\n",
    "<img src=\"./images/forecast.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ann_visualizer\n",
    "#!pip install sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of the circles dataset with points colored by class\n",
    "from sklearn.datasets import make_circles\n",
    "from numpy import where\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# mlp for the two circles classification problem\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import RandomUniform\n",
    "\n",
    "# Figure Plotting libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function to plot decision boundaries\n",
    "def plot_decision_boundary(X, y, model, steps=1000, cmap='Paired'):\n",
    "    \"\"\"\n",
    "    Function to plot the decision boundary and data points of a model.\n",
    "    Data points are colored based on their actual label.\n",
    "    \"\"\"\n",
    "    cmap = plt.get_cmap(cmap)\n",
    "    \n",
    "    # Define region of interest by data limits\n",
    "    xmin, xmax = X[:,0].min() - 1, X[:,0].max() + 1\n",
    "    ymin, ymax = X[:,1].min() - 1, X[:,1].max() + 1\n",
    "    steps = 100\n",
    "    x_span = np.linspace(xmin, xmax, steps)\n",
    "    y_span = np.linspace(ymin, ymax, steps)\n",
    "    xx, yy = np.meshgrid(x_span, y_span)\n",
    "\n",
    "    # Make predictions across region of interest\n",
    "    labels = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Plot decision boundary in region of interest\n",
    "    z = labels.reshape(xx.shape)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.contourf(xx, yy, z, cmap=cmap, alpha=0.5)\n",
    "\n",
    "    # Get predicted labels on training data and plot\n",
    "    train_labels = model.predict(X)\n",
    "    ax.scatter(X[:,0], X[:,1], c=y, cmap=cmap, lw=0)\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Learning Network with ReLu Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In workshop 2B, you had to classify a breast tumour dataset using Naive Bayes algorithm. In this task, you will do classify again the dataset, but using:\n",
    "\n",
    "- (1) a neural network with the 'tanh' as the activation function (you can choose as many hidden layers as you want)\n",
    "- (2) a deep neural network with the 'relu' activation function (you can choose as many hidden layers as you want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's revisit the breast cancer dataset\n",
    "\n",
    "file_path = 'data/breast_data_simple.csv'\n",
    "data = pd.read_csv( file_path )\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"radius_mean\", \"texture_mean\"]]\n",
    "y = data[\"diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting purposes:\n",
    "# separate the benign tumors (diagnosis = 0) from the malignant ones (diagnosis = 1)\n",
    "malignant = data[ data[ 'diagnosis'] == 1]\n",
    "benign = data[ data[ 'diagnosis'] == 0]\n",
    "\n",
    "# need to convert dataframe into a matrix in order to make the plot work\n",
    "x = X.to_numpy()\n",
    "\n",
    "# plot figure\n",
    "fig=plt.figure(dpi=150)\n",
    "\n",
    "plt.scatter(malignant['radius_mean'], malignant['texture_mean'], c='r', marker='x', s=10, label='malignant', cmap='RdBu')\n",
    "plt.scatter(benign['radius_mean'], benign['texture_mean'], c='b', marker='o', s=10, label='benign', cmap='RdBu')\n",
    "plt.ylabel('texture_mean', fontsize=12)\n",
    "plt.xlabel('radius_mean', fontsize=12)\n",
    "plt.title('Breast Tumors', fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# separate the dataset into test set, validation set and train set\n",
    "# YOUR CODE HERE:\n",
    "#X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.3 )\n",
    "# create the training set and the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 515)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state = 515)\n",
    "\n",
    "# define the Machine Learning Model: Neural Network\n",
    "# YOUR CODE HERE:\n",
    "model_tum = Sequential()\n",
    "\n",
    "# add the required layers\n",
    "# YOUR CODE HERE:\n",
    "model_tum.add(Dense(10, input_dim=2, activation='tanh'))\n",
    "\n",
    "model_tum.add(Dense(7, activation='tanh'))\n",
    "model_tum.add(Dense(3, activation='tanh'))\n",
    "model_tum.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the network using: \n",
    "# the 'mean_squared_error' as a loss function\n",
    "# the stochastic gradient descent ('sgd') as the optimization function\n",
    "# and the 'accuracy' as evaluation metric\n",
    "# YOUR CODE HERE:\n",
    "model_tum.compile(loss='mean_squared_error', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "# fit the model to the data -> learning the model\n",
    "# YOUR CODE HERE:\n",
    "# fit model\n",
    "history = model_tum.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=300, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "# evaluate the model\n",
    "_, train_acc = model_tum.evaluate(X_train, y_train, verbose=1)\n",
    "_, test_acc = model_tum.evaluate(X_test, y_test, verbose=1)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='val')\n",
    "pyplot.ylabel('accuracy', fontsize=12)\n",
    "pyplot.xlabel('iterations', fontsize=12)\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='val')\n",
    "pyplot.ylabel('loss', fontsize=12)\n",
    "pyplot.xlabel('iterations', fontsize=12)\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
